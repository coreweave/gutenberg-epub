# This is a workflow that pulls down the gutenberg library hosted on CW S3,
# unzips it, parses it over ~1hour, then uploads it again

name: Parse and Upload

# Controls when the workflow will run
on:
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  parse:
    # Runs on CW large org runner
    runs-on: ${{ fromJSON(inputs.large-runner && '["self-hosted", "Linux", "chunky"]' || '["self-hosted", "Linux"]') }}

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3

      # install sudo
      - name: Install sudo
        run: apt-get install -y sudo

      # Install other Deps
      - name: Install Deps
        run: sudo apt update && sudo apt install -y python3 python3-pip zip unzip && pip install s3cmd


      # pull down s3 gutenberg lib
      - name: S3 Download Gutenberg
        env:
          s3accesskey: ${{ secrets.ACTION_S3_ACCESSKEY }}
          s3base: ${{ secrets.ACTION_S3_BASE }}
          s3bucket: ${{ secrets.ACTION_S3_BUCKET }}
          s3secretkey: ${{ secrets.ACTION_S3_SECRETKEY }}
        run: s3cmd --access_key $s3accesskey --host $s3base --host-bucket $s3bucket --secret_key $s3secretkey get s3://gutenberg/pg-calibre-library.zip

      #unzip gutenberg data
      - name: Unzip Source
        run: unzip pg-calibre-library.zip

      # Run a fast parse to test
      - name: Fast Parse
        run: ./gutenberg-epub-converter -inputDir ./pg-calibre-library -outputDir ./Author -writeHeader=true -writeMetadata=false -cleanOutput=true -seperateFolders=false -stopEarly=0 -skipCopyRight=true -gutenbergCleaning=true -createSubsets=author

      #zip gutenberg data
      - name: Zip Results
        run: zip -r Author.zip Author

      #Upload to S3
      - name: Upload to S3
        env:
          s3accesskey: ${{ secrets.ACTION_S3_ACCESSKEY }}
          s3base: ${{ secrets.ACTION_S3_BASE }}
          s3bucket: ${{ secrets.ACTION_S3_BUCKET }}
          s3secretkey: ${{ secrets.ACTION_S3_SECRETKEY }}
        run: s3cmd --access_key $s3accesskey --host $s3base --host-bucket $s3bucket --secret_key $s3secretkey --no-check-hostname --no-check-certificate put ./Author.zip s3://gutenberg --recursive --multipart-chunk-size-mb=50 -H --progress --stats 

      #lists s3cmd files, to check its working
      - name: Test show S3 files
        env:
          s3accesskey: ${{ secrets.ACTION_S3_ACCESSKEY }}
          s3base: ${{ secrets.ACTION_S3_BASE }}
          s3bucket: ${{ secrets.ACTION_S3_BUCKET }}
          s3secretkey: ${{ secrets.ACTION_S3_SECRETKEY }}
        run: s3cmd --access_key $s3accesskey --host $s3base --host-bucket $s3bucket --secret_key $s3secretkey --no-check-hostname --no-check-certificate la

